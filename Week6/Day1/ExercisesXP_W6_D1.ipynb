{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moaadouhmad99-ops/DI_Bootcamp/blob/main/Week6/Day1/ExercisesXP_W6_D1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebaf841d",
      "metadata": {
        "id": "ebaf841d"
      },
      "source": [
        "# Exercises XP: Student Notebook\n",
        "\n",
        "For each exercise, the **Instructions** from the plateform are guided, and the **Guidance** explains exactly what you must do to complete the task."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c0f244",
      "metadata": {
        "id": "f2c0f244"
      },
      "source": [
        "## What you will learn\n",
        "- How to clearly define and articulate a machine learning problem statement.\n",
        "\n",
        "- The process of data collection, including identifying relevant data types and potential data sources.\n",
        "Skills in feature selection and justification for machine learning models, particularly in the context of loan default prediction.\n",
        "\n",
        "- Understanding of different types of machine learning models and their suitability for various real-world scenarios.\n",
        "\n",
        "- Techniques and strategies for evaluating the performance of different machine learning models, including choosing appropriate metrics and understanding their implications."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17aa83e3",
      "metadata": {
        "id": "17aa83e3"
      },
      "source": [
        "## What you will create\n",
        "- A detailed problem statement and data collection plan for a loan default prediction project, including identification of key data types and sources.\n",
        "- A comprehensive feature selection analysis for a hypothetical loan default prediction dataset.\n",
        "- A theoretical evaluation strategy for three different types of machine learning models, addressing the unique challenges and metrics relevant to each model type.\n",
        "- Thoughtful analyses and justifications for choosing specific machine learning approaches for varied scenarios such as stock price prediction, library organization, and robot navigation.\n",
        "- A document or presentation that showcases your understanding and approach to evaluating and optimizing machine learning models in diverse contexts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e965f9",
      "metadata": {
        "id": "93e965f9"
      },
      "source": [
        "## ðŸŒŸ Exercise 1 : Defining the Problem and Data Collection for Loan Default Prediction\n",
        "\n",
        "### Instructions\n",
        "- Write a clear problem statement for predicting loan defaults.\n",
        "- Identify and list the types of data you would need for this project (e.g., personal details of applicants, credit scores, loan amounts, repayment history).\n",
        "- Discuss the sources where you can collect this data (e.g., financial institutionâ€™s internal records, credit bureaus).\n",
        "\n",
        "**Expected Output:** A document detailing the problem statement and a comprehensive plan for data collection, including data types and sources."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ea95bd",
      "metadata": {
        "id": "62ea95bd"
      },
      "source": [
        "### Guidance\n",
        "- Please write your answer as a short document. Begin by stating the prediction objective in a complete sentence that names the target variable and the decision it will support. Then, describe the data types you would collect in complete sentences. For each data type, explain in one sentence why it could help predict loan defaults.\n",
        "\n",
        "- After that, name realistic data sources in complete sentences, and briefly describe how you would obtain or integrate each source.\n",
        "\n",
        "- Finally, include one paragraph that explains risks and constraints such as privacy, regulation, data quality, sampling bias, and governance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b165d7a",
      "metadata": {
        "id": "9b165d7a"
      },
      "source": [
        "### Your answer\n",
        "\n",
        "The goal is to predict whether a loan applicant will default (yes/no) to support loan approval and risk decisions.\n",
        "\n",
        "I would collect demographic, financial, credit history, loan, and banking behavior data because they directly affect repayment ability and risk.\n",
        "\n",
        "Data would be collected from internal bank systems, credit bureaus via secure APIs, and government financial data portals.\n",
        "\n",
        "Key risks include privacy compliance, data quality issues, sampling bias, and the need for strong data governance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c297407",
      "metadata": {
        "id": "7c297407"
      },
      "source": [
        "## ðŸŒŸ Exercise 2 : Feature Selection and Model Choice for Loan Default Prediction\n",
        "\n",
        "### Instructions\n",
        "From this dataset, identify which features might be most relevant for predicting loan defaults.\n",
        "Justify your choice of features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4deb8c95",
      "metadata": {
        "id": "4deb8c95"
      },
      "source": [
        "### Guidance\n",
        "- First, identify the features that you believe are most relevant, and write their names in a sentence.\n",
        "Then, provide a justification in complete sentences that explains how each selected feature relates to the likelihood of default.\n",
        "\n",
        "- If you decide to exclude common features, write one sentence for each excluded feature to explain why it is not appropriate in this context.\n",
        "\n",
        "- Conclude with two complete sentences that explain how you would encode categorical features and how you would impute missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af9600b",
      "metadata": {
        "id": "3af9600b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f15f62-c68a-4de0-9d3f-7e364387fc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You will now justify the selected features in complete sentences below.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This piece of code is already prefilled, run it to execute it and see the results.\n",
        "# It provides a simple template you can modify while writing your justification.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# This placeholder DataFrame allows the cell to run even if you did not load a dataset yet.\n",
        "example_columns = [\n",
        "    \"age\",\"employment_length\",\"annual_income\",\"credit_score\",\"loan_amount\",\"interest_rate\",\n",
        "    \"debt_to_income\",\"num_delinquencies\",\"num_open_accounts\",\"total_utilization\",\"home_ownership\",\n",
        "    \"purpose\",\"term\",\"application_type\",\"state\",\"zip_code\"\n",
        "]\n",
        "df = pd.DataFrame(columns=example_columns)\n",
        "\n",
        "# Please replace this list with the actual columns that you select.\n",
        "selected_features = [\n",
        "    # e.g., \"credit_score\",\"debt_to_income\",\"annual_income\",\"loan_amount\",\"interest_rate\",\n",
        "    # \"employment_length\",\"num_delinquencies\",\"total_utilization\"\n",
        "]\n",
        "\n",
        "print(\"You will now justify the selected features in complete sentences below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0e3a74",
      "metadata": {
        "id": "ed0e3a74"
      },
      "source": [
        "### Your justification\n",
        "\n",
        "The most relevant features are credit_score, debt_to_income, annual_income, loan_amount, interest_rate, employment_length, num_delinquencies, and total_utilization.\n",
        "\n",
        "These features are important because they reflect credit behavior, income stability, debt burden, and financial stress, which strongly influence default risk.\n",
        "\n",
        "I excluded zip_code, state, and application_type because they can introduce bias and have low direct predictive value.\n",
        "\n",
        "I would use one-hot encoding for categorical variables and median or mode imputation for missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8e6708",
      "metadata": {
        "id": "9e8e6708"
      },
      "source": [
        "## ðŸŒŸ Exercise 3 : Training, Evaluating, and Optimizing the Model\n",
        "\n",
        "### Instructions\n",
        "Which model(s) would you pick for a Loan Prediction ?\n",
        "Outline the steps to evaluate the modelâ€™s performance, mentioning specific metrics that would be relevant to evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe22b7ce",
      "metadata": {
        "id": "fe22b7ce"
      },
      "source": [
        "### Guidance\n",
        "- Begin by naming one or two candidate models in a complete sentence and explain why each model is suitable for this problem.\n",
        "\n",
        "- Next, describe an evaluation plan in complete sentences that covers the data split, the cross-validation strategy, the metrics you will report, and how you will choose a decision threshold.\n",
        "\n",
        "- Then, explain in complete sentences how you will address class imbalance using stratification, class weights, or resampling.\n",
        "\n",
        "- Finally, state in one or two complete sentences how you would iterate on hyperparameters to improve performance while avoiding data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d630ee52",
      "metadata": {
        "id": "d630ee52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d29694f-8f0d-4e3b-88e6-88f91f21a84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "ROC-AUC: 1.0\n",
            "PR-AUC (Average Precision): 1.0\n",
            "\n",
            "Confusion matrix:\n",
            " [[6 0]\n",
            " [0 4]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This piece of code is already prefilled, run it to execute it and see the results.\n",
        "# It demonstrates standard classification metrics for binary loan default prediction.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
        "\n",
        "# Please replace these placeholders with your true labels and predicted probabilities.\n",
        "y_true = [0,1,0,1,0,0,1,0,1,0]            # placeholder labels\n",
        "y_pred_proba = [0.05,0.80,0.10,0.65,0.20,0.15,0.70,0.30,0.85,0.25]  # placeholder probabilities\n",
        "\n",
        "# You should set a decision threshold that reflects the precisionâ€“recall trade-off for your business case.\n",
        "threshold = 0.5\n",
        "y_pred = [1 if p >= threshold else 0 for p in y_pred_proba]\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 4))\n",
        "print(\"Precision:\", round(precision_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"Recall:\", round(recall_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"F1-score:\", round(f1_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_true, y_pred_proba), 4))\n",
        "print(\"PR-AUC (Average Precision):\", round(average_precision_score(y_true, y_pred_proba), 4))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd4054c",
      "metadata": {
        "id": "cdd4054c"
      },
      "source": [
        "### Your answer\n",
        "\n",
        "I would use Logistic Regression and Gradient Boosting because they work well for binary classification and capture both linear and non-linear patterns.\n",
        "\n",
        "I would use stratified train/validation/test splits, k-fold cross-validation, and evaluate using precision, recall, F1-score, ROC-AUC, and PR-AUC with a business-driven threshold.\n",
        "\n",
        "I would handle class imbalance using class weights and resampling methods.\n",
        "\n",
        "I would tune hyperparameters on validation data only to avoid data leakage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0488eb67",
      "metadata": {
        "id": "0488eb67"
      },
      "source": [
        "## ðŸŒŸ Exercise 4 : Designing Machine Learning Solutions for Specific Problems\n",
        "\n",
        "### Instructions\n",
        "For each of these scenario, decide which type of machine learning would be most suitable. Explain.\n",
        "\n",
        "Predicting Stock Prices : predict future prices\n",
        "Organizing a Library of Books : group books into genres or categories based on similarities.\n",
        "Program a robot to navigate and find the shortest path in a maze."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c00056",
      "metadata": {
        "id": "00c00056"
      },
      "source": [
        "### Guidance\n",
        "Please identify the appropriate machine learning paradigm for each scenario in complete sentences and justify your choice.\n",
        "\n",
        "For each scenario, write one complete sentence that describes the input data, one complete sentence that describes the output, and one complete sentence that describes the learning signal or objective."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27bd365",
      "metadata": {
        "id": "d27bd365"
      },
      "source": [
        "### Your answer\n",
        "\n",
        "For stock price prediction, supervised time-series learning is best; the input is historical market data, the output is future prices, and the objective is to minimize prediction error.\n",
        "\n",
        "For organizing books, unsupervised clustering is best; the input is book metadata, the output is clusters, and the objective is to group similar books.\n",
        "\n",
        "For robot navigation, reinforcement learning is best; the input is sensor and position data, the output is actions, and the objective is to maximize cumulative reward.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8e44a7",
      "metadata": {
        "id": "2e8e44a7"
      },
      "source": [
        "## ðŸŒŸ Exercise 5 : Designing an Evaluation Strategy for Different ML Models\n",
        "\n",
        "### Instructions\n",
        "- Select three types of machine learning models: one from supervised learning (e.g., a classification model), one from unsupervised learning (e.g., a clustering model), and one from reinforcement learning. - For the supervised model, outline a strategy to evaluate its performance, including the choice of metrics (like accuracy, precision, recall, F1-score) and methods (like cross-validation, ROC curves).\n",
        "- For the unsupervised model, describe how you would assess the effectiveness of the model, considering techniques like silhouette score, elbow method, or cluster validation metrics.\n",
        "- For the reinforcement learning model, discuss how you would measure its success, considering aspects like cumulative reward, convergence, and exploration vs. exploitation balance.\n",
        "- Address the challenges and limitations of evaluating models in each category."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f13dd9",
      "metadata": {
        "id": "f6f13dd9"
      },
      "source": [
        "### Guidance\n",
        "- Please write a separate paragraph for each of the three model categories.\n",
        "- In the supervised paragraph, describe your validation plan and list the metrics you will report in complete sentences.\n",
        "- In the unsupervised paragraph, explain how you would measure cluster quality or structure in complete sentences and mention any diagnostic plots.\n",
        "- In the reinforcement learning paragraph, describe how you would track cumulative reward, assess convergence, and balance exploration and exploitation using complete sentences.\n",
        "Conclude with one complete sentence per category that states a key evaluation challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff6d0257",
      "metadata": {
        "id": "ff6d0257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d294c51-e685-4375-f284-cbfad2c9ad5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "ROC-AUC: 1.0\n",
            "PR-AUC (Average Precision): 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This piece of code is already prefilled, run it to execute it and see the results.\n",
        "# Supervised classification metrics template with placeholders.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
        "\n",
        "# Replace these placeholders with your real outputs.\n",
        "y_true = [0,1,1,0,1,0,0,1,0,1]\n",
        "y_pred_proba = [0.1,0.7,0.8,0.2,0.6,0.3,0.4,0.9,0.2,0.85]\n",
        "threshold = 0.5\n",
        "y_pred = [1 if p >= threshold else 0 for p in y_pred_proba]\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 4))\n",
        "print(\"Precision:\", round(precision_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"Recall:\", round(recall_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"F1-score:\", round(f1_score(y_true, y_pred, zero_division=0), 4))\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_true, y_pred_proba), 4))\n",
        "print(\"PR-AUC (Average Precision):\", round(average_precision_score(y_true, y_pred_proba), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3c51e0",
      "metadata": {
        "id": "cf3c51e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f351b3-d880-446d-b386-7fd6ac588c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score (higher is better): 0.848\n",
            "Please explain in complete sentences when you would use the elbow method and how you would interpret it.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# This piece of code is already prefilled, run it to execute it and see the results.\n",
        "# Unsupervised clustering metrics template with synthetic data.\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "X, _ = make_blobs(n_samples=300, centers=3, random_state=42)\n",
        "kmeans = KMeans(n_clusters=3, n_init=\"auto\", random_state=42)\n",
        "labels = kmeans.fit_predict(X)\n",
        "sil = silhouette_score(X, labels)\n",
        "print(\"Silhouette score (higher is better):\", round(sil, 4))\n",
        "\n",
        "print(\"Please explain in complete sentences when you would use the elbow method and how you would interpret it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7d9f0ef",
      "metadata": {
        "id": "e7d9f0ef"
      },
      "source": [
        "### My answer\n",
        "\n",
        "For supervised models, I would use cross-validation and report accuracy, precision, recall, F1-score, ROC-AUC, and PR-AUC, with class imbalance as the main challenge.\n",
        "\n",
        "For unsupervised models, I would use silhouette score and the elbow method to evaluate clusters, with the main challenge being the lack of labels.\n",
        "\n",
        "For reinforcement learning, I would track cumulative reward and convergence while balancing exploration and exploitation, with unstable training as the main challenge.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}